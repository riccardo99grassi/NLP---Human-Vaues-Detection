{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRcn_0DKmFSN"
      },
      "source": [
        "# Fine Tuning Transformers for identification of Human Values behind Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "\n",
        "In this notebook we will be fine tuning different transformer models\n",
        "for the **detection of human values** given a specifc argument. It consists of a **Multilabel text classification** problem where a given piece of text needs to be classified into one or more categories out of the given list. For example, as in this case, a given argument can be categorized into 1 or more human values.\n",
        "\n",
        "#### Flow of the notebook\n",
        "\n",
        "The notebook will be divided into seperate sections to provide a organized walk through for the process used. The sections are:\n",
        "\n",
        "1. [Importing Python Libraries and preparing the environment](#section01)\n",
        "2. [Importing and Pre-Processing the domain data](#section02)\n",
        "3. [Preparing the Dataset and Dataloader](#section03)\n",
        "4. [Creating the Neural Network for Fine Tuning](#section04)\n",
        "5. [Fine Tuning the Model](#section05)\n",
        "6. [Validating the Model Performance](#section06)\n",
        "7. [Evaluating the best model](#section07)\n",
        "8. [Choosing the best threshold](#section08)\n",
        "9. [Results](#section09)\n",
        "\n",
        "#### Technical Details\n",
        "\n",
        " - Data: \n",
        "\t - We are using the data available on [Zenodo](https://zenodo.org/record/7550385#.Y8wMquzMK3I)\n",
        "     - [Human Value Detection 2023](https://touche.webis.de/semeval23/touche23-web/index.html) is the competion which provide the souce dataset\n",
        "\t - We are referring only to the following data: `arguments-training.tsv`, `arguments-validation`, `labels-training.tsv`, `labels-validation.tsv`\n",
        "\t \n",
        "     - `arguments-<split>.tsv`: Each row corresponds to one argument\n",
        "        - `Argument ID`: The unique identifier for the argument\n",
        "        - `Conclusion`: Conclusion text of the argument\n",
        "        - `Stance`: Stance of the Premise towards the Conclusion; one of \"in favor of\", \"against\"\n",
        "        - `Premise`: Premise text of the argument\n",
        "\n",
        "     - `labels-<split>.tsv`: Each row corresponds to one argument\n",
        "        - `Argument ID`: The unique identifier for the argument\n",
        "        - `Other`: Each other column corresponds to one value category, with a 1 meaning that the argument resorts to the value category and a 0 that not\n",
        "---\n",
        "***NOTE***\n",
        "- *Since test data are provided without labels, we did not consider them for our analysis. In this regards **the performances of our models have been tested only on validation data**.*\n",
        "---\n",
        "  \n",
        " - Language Model Used:\n",
        "\t - BERT BASE\n",
        "     - BERT LARGE\n",
        "     - ROBERTA BASE\n",
        "     - ROBERTA LARGE\n",
        "     - DISTILBERT\n",
        "---\n",
        "***NOTE***\n",
        "\n",
        "- Auto Models\n",
        "    - As explained by [Hugging Face doc](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html), in many cases, the architecture we want to use can be guessed from the name or the path of the pretrained model we are supplying to the `from_pretrained` method.\n",
        "    AutoClasses are here to do this job for us so that we automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary:\n",
        "        - Instantiating one of `AutoModel` and `AutoTokenizer` will directly create a class of the relevant architecture \n",
        "(ex: model = AutoModel.from_pretrained('bert-base-cased') will create a instance of BertModel).\n",
        "---\n",
        "\n",
        " - Hardware Requirements:\n",
        "\t - Python 3.6 and above\n",
        "\t - Pytorch, Transformers and All the stock Python ML Libraries\n",
        "\t - GPU enabled setup \n",
        "\n",
        "\n",
        " - Script Objective:\n",
        "\t - Fine tuning of different transformer models such that: given a textual argument, classify whether or not the argument draws on one of the following categories:\n",
        "        * Self-direction: thought      \n",
        "        * Self-direction: action       \n",
        "        * Stimulation     \n",
        "        * Hedonism       \n",
        "        * Achievement      \n",
        "        * Power: dominance       \n",
        "        * Power: resources       \n",
        "        * Face       \n",
        "        * Security: personal      \n",
        "        * Security: societal      \n",
        "        * Tradition       \n",
        "        * Conformity: rules       \n",
        "        * Conformity: interpersonal       \n",
        "        * Humility       \n",
        "        * Benevolence: caring       \n",
        "        * Benevolence: dependability      \n",
        "        * Universalism: concern       \n",
        "        * Universalism: nature       \n",
        "        * Universalism: tolerance      \n",
        "        * Universalism: objectivity       \n",
        "\n",
        "---\n",
        "***NOTE***\n",
        "- *It is to be noted that the overall mechanisms for a multiclass and multilabel problems are similar, except for few differences namely:*\n",
        "\t- *Loss function is designed to evaluate all the probability of categories individually rather than as compared to other categories. Hence the use of `BCE` rather than `Cross Entropy` when defining loss.*\n",
        "\t- *Sigmoid of the outputs calcuated to rather than Softmax. Again for the reasons defined in the previous point*\n",
        "\t- *The [accuracy metrics](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) and [F1 scores](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) used from sklearn package as compared to direct comparison of expected vs predicted*\n",
        "---"
      ],
      "metadata": {
        "id": "2607wHvlBE7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section01'></a>\n",
        "### Importing Python Libraries and preparing the environment\n",
        "\n",
        "At this step we will be importing the libraries and modules needed to run our script. Libraries are:\n",
        "* Numpy\n",
        "* Pandas\n",
        "* Pytorch\n",
        "* Pytorch Utils for Dataset and Dataloader\n",
        "* Transformers\n",
        "* AutoModel and AutoTokenizer\n",
        "\n",
        "Followed by that we will preapre the device for GPU execeution. This configuration is needed if you want to leverage on onboard GPU.\n",
        "\n",
        "RANDOM SEED has been settled to 42 to ensure experiments reproducibility."
      ],
      "metadata": {
        "id": "A71JDmR2NbKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WD_vnyLXZQzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27655a47-c489-4f8a-c3e3-144391479494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing the transformers library and additional libraries if looking process \n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pzM1_ykHaFur"
      },
      "outputs": [],
      "source": [
        "# Importing stock ml libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLIVC5sCIC39",
        "outputId": "43259152-7c9b-4b62-fabe-4b6ac3b1459d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_weights_bert_base = 'drive/MyDrive/Pesi_NLP/bert_base.pth'\n",
        "best_weights_bert_large = 'drive/MyDrive/Pesi_NLP/bert_large.pth'\n",
        "best_weights_roberta_base = 'drive/MyDrive/Pesi_NLP/roberta-base.pth'\n",
        "best_weights_roberta_large = 'drive/MyDrive/Pesi_NLP/roberta_large.pth'\n",
        "best_weights_distilbert = 'drive/MyDrive/Pesi_NLP/distilbert.pth'"
      ],
      "metadata": {
        "id": "ZDGGOzSQIUI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed to repeat experiments.\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAU42Itr7vP1",
        "outputId": "a7909efd-0d8d-4817-ce51-bc13b8c0031b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe9a3ed5710>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NLxxwd1scQNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637b9687-db05-444c-9d91-e3fd61fac03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda.\n"
          ]
        }
      ],
      "source": [
        "# # Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Using {device}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section02'></a>\n",
        "### Importing and Pre-Processing the domain data\n",
        "\n",
        "We will be working with the data and preparing for fine tuning purposes, *assuming that the `arguments-train.tsv`, `labels-train.tsv`, `arguments-validation.tsv`, `labels-validation.tsv` are already downloaded and saved in our `data` folder*\n",
        "\n",
        "* Import files in different dataframes\n",
        "* Merge arguments and labels dataframe of each corresponding split \n",
        "* Taking the values of all the categories and coverting it into a list.\n",
        "* The list is appened as a new column and other columns are removed"
      ],
      "metadata": {
        "id": "7HvSHQjiOlD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mZ7lTlkyaG7u"
      },
      "outputs": [],
      "source": [
        "args_train = pd.read_csv(\"arguments-training.tsv\", delimiter='\\t')\n",
        "labels_train = pd.read_csv(\"labels-training.tsv\", delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = args_train.merge(labels_train)\n",
        "df['list'] = df[df.columns[4:]].values.tolist()\n",
        "df['text'] = df.Conclusion+\" \"+df.Stance+\" \"+df.Premise\n",
        "df_train = df[['text', 'list']].copy()\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o8vQuBfEuBiE",
        "outputId": "423629b1-35f9-4b48-8dd2-61040bc22fde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  We should ban human cloning in favor of we sho...   \n",
              "1  We should ban fast food in favor of fast food ...   \n",
              "2  We should end the use of economic sanctions ag...   \n",
              "3  We should abolish capital punishment against c...   \n",
              "4  We should ban factory farming against factory ...   \n",
              "\n",
              "                                                list  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72093b66-8992-49e6-9276-e0fd83f42f7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We should ban human cloning in favor of we sho...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We should ban fast food in favor of fast food ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We should end the use of economic sanctions ag...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We should abolish capital punishment against c...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We should ban factory farming against factory ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72093b66-8992-49e6-9276-e0fd83f42f7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72093b66-8992-49e6-9276-e0fd83f42f7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72093b66-8992-49e6-9276-e0fd83f42f7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args_test = pd.read_csv(\"arguments-validation.tsv\", delimiter='\\t')\n",
        "labels_test = pd.read_csv(\"labels-validation.tsv\", delimiter='\\t')"
      ],
      "metadata": {
        "id": "F-7bEo78wUdc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = args_test.merge(labels_test)\n",
        "df['list'] = df[df.columns[4:]].values.tolist()\n",
        "df['text'] = df.Conclusion+\" \"+df.Stance+\" \"+df.Premise\n",
        "df_test = df[['text', 'list']].copy()\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x4xeWOy4wfss",
        "outputId": "aab70927-8769-4862-81a5-97e2a8714723"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Entrapment should be legalized in favor of if ...   \n",
              "1  The use of public defenders should be mandator...   \n",
              "2  Payday loans should be banned in favor of payd...   \n",
              "3  Surrogacy should be banned against Surrogacy s...   \n",
              "4  Entrapment should be legalized against entrapm...   \n",
              "\n",
              "                                                list  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c9a8980-7f08-4594-a14a-bfa03e1f97ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Entrapment should be legalized in favor of if ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The use of public defenders should be mandator...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Payday loans should be banned in favor of payd...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Surrogacy should be banned against Surrogacy s...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Entrapment should be legalized against entrapm...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c9a8980-7f08-4594-a14a-bfa03e1f97ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c9a8980-7f08-4594-a14a-bfa03e1f97ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c9a8980-7f08-4594-a14a-bfa03e1f97ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section03'></a>\n",
        "### Preparing the Dataset and Dataloader\n",
        "We will go through the following workflow:\n",
        "1. Definition of global variables that will be used later \n",
        "during the training/fine tuning stage.\n",
        "2. Creation of CustomDataset class - This defines how the text is pre-processed before sending it to the neural network. \n",
        "3. Definiition of the Dataloader that will feed  the data in batches to the neural network for suitable training and processing. \n",
        "---\n",
        "***NOTE***\n",
        "\n",
        "Dataset and Dataloader are constructs of the [PyTorch library](https://pytorch.org/docs/stable/data.html) for defining and controlling the data pre-processing and its passage to neural network.\n"
      ],
      "metadata": {
        "id": "6VQlrH7NSr9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definition of global variables"
      ],
      "metadata": {
        "id": "Po0fklDiWH61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ikfbFlNHgi8T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "9bc33332ccc849ef874a48158a14a4b5",
            "bee90653ad614fae92d67206bad420c9",
            "f84b2d3c97f04661933a8759ebc87f08",
            "fde85dd33592434288703e0fe28ed19e",
            "15b4780b911443d38d4b8d136412146f",
            "d422c5b0e00643f781ba12749c83821c",
            "d145e7dda365482cbd08fcfc7e5f4529",
            "8ba169da0b5a4018aa793e756d6be2d7",
            "0210959d908848b3a5ade43f4d6abb5b",
            "e5010691d070417f97c7f644c1a205da",
            "2bea7e1a55e44f668ae331248dc73d6f",
            "6407b2bc74fe41248604ca37a07d931c",
            "b6056d2a88cf4976ba1c6120b6b67e28",
            "b41234f575b24bd699501c8311ebb182",
            "21ddf52d62e54a0787f9a4460ad5fe99",
            "0f9c4064572d4a698a5ac91ea3ca06f8",
            "8ef5de2b5c424c0280a98eecca5df1f5",
            "c98adddbc75b457bbec5b8f2d8d2153e",
            "a4e1bfecf47d4998b3111d7956dd40b8",
            "36dbd4a1a5d74ec5a8a2bc4e1f97f184",
            "cf52283a3b0c44f4ae56380966b55041",
            "74b62adfdb5d4b4794d16077f1eba7b2",
            "71d288315f0348c6a5caa1c64e71f1ff",
            "e87f61899b9245f890c8234100f82ff6",
            "81152743d6344bac88ea081a23727166",
            "3d8dbc465730415687f4cb13ed2b2791",
            "8329fc4a6777404998b0ed61cb0c92f0",
            "63d947cc07f94e2a9a645bc3076303e9",
            "6587c79566de48f29624b5ba28e847e2",
            "495ca330ee8a42989f3471551b0f16ae",
            "4d9523b5ec454ddca722f6ec602ecca4",
            "a679f22327344ebebd23dec367ac49f5",
            "0381019a16254c5e97befce45fd05d58",
            "cd06cb104d0649fab7ee39a0aa0e0799",
            "64b8e628b5e94716ba6c99ad836e47d5",
            "4e1c35f5bed446cdbd9f091095714dda",
            "76e5f05dd7344984b57b021b86a70322",
            "222fc947ee7b436782c43a53c6252cff",
            "e17d5a70e2644c1fab29f6b9755334ac",
            "dfbf7a39c83440bb9f9e0ef278a78669",
            "26e0d0ded1a94b08848a784eb8050d4a",
            "126654647bc649b1a303d1e96d2c858e",
            "fb118445265a457997a1e61c6d22170d",
            "4383abd1855444438db41171f1ec4c64"
          ]
        },
        "outputId": "3f71b67c-e9c4-406b-b5e9-81f24a352a0c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bc33332ccc849ef874a48158a14a4b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6407b2bc74fe41248604ca37a07d931c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71d288315f0348c6a5caa1c64e71f1ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd06cb104d0649fab7ee39a0aa0e0799"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "#MODEL_NAME = 'bert-base-uncased'\n",
        "#MODEL_NAME = 'bert-large-uncased'\n",
        "#MODEL_NAME = 'roberta-base'\n",
        "MODEL_NAME = 'roberta-large'\n",
        "#MODEL_NAME = 'distilbert-base-uncased'\n",
        "\n",
        "MAX_LEN = 75\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 2e-05\n",
        "OUT_CHANNELS = 768 if \"base\" in  MODEL_NAME else 1024\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### *CustomDataset* Dataset Class\n",
        "- This class is defined to accept the `tokenizer`, `dataframe` and `max_length` as input and generate tokenized output and tags that is used by the BERT/ROBERTA/DISTILBERT model for training. \n",
        "- We are using the BERT/ROBERTA/DISTILBERT tokenizer to tokenize the data in the `comment_text` column of the dataframe.\n",
        "- The tokenizer uses the `encode_plus` method to perform tokenization and generate the necessary outputs, namely: `ids`, `attention_mask`, `token_type_ids` (*the latter is not generated by DISTILBERT tokenizer*)\n",
        "\n",
        "- `targest` is the list of categories labled as `0` or `1` in the dataframe. \n",
        "- The *CustomDataset* class is used to create 2 datasets, for training and for validation.\n",
        "- *Training Dataset* is used to fine tune the model.\n",
        "- *Validation Dataset* is used to evaluate the performance of the model. "
      ],
      "metadata": {
        "id": "iH9wr23MWULM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oFOylAXqiNYK"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = self.data.list #labels\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkDGqarcPowL",
        "outputId": "869d8795-91de-4769-dd45-4abd3b0ea783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (5393, 2)\n",
            "TEST Dataset: (1896, 2)\n"
          ]
        }
      ],
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(df_train.shape))\n",
        "print(\"TEST Dataset: {}\".format(df_test.shape))\n",
        "\n",
        "training_set = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(df_test, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataloader\n",
        "- Dataloader is used to create training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of data loaded to the memory and then passed to the neural network needs to be controlled.\n",
        "- This control is achieved using the parameters such as `batch_size` and `max_len`.\n",
        "- Training and Validation dataloaders are used in the training and validation part of the flow respectively"
      ],
      "metadata": {
        "id": "TqMWh_JtVdHP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vLpilV73QrXJ"
      },
      "outputs": [],
      "source": [
        "training_loader = DataLoader(training_set, batch_size = BATCH_SIZE)\n",
        "testing_loader = DataLoader(testing_set, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section04'></a>\n",
        "\n",
        "#### Neural network\n",
        "We will be creating a neural network with either the `BERTClass` or `DistilbertClass` depending on the established `MODEL_NAME`. \n",
        "\n",
        "##### BERTClass\n",
        "\n",
        "- This network will have the `Bert` / `Roberta` model follwed by a `Droput` and `Linear Layer`. They are added for the purpose of **Regulariaztion** and **Classification** respectively. \n",
        "- In the forward loop, there are 2 output from the `BertModel` / `RobertaModel` layer.\n",
        "- The second output `output_1` or called the `pooled output` is passed to the `Drop Out layer` and the subsequent output is given to the `Linear layer`. \n",
        "- Keep note the number of dimensions for `Linear Layer` is **20** because that is the total number of categories in which we are looking to classify our model.\n",
        "- The data will be fed to the `BertClass` as defined in the dataset. \n",
        "- Final layer outputs is what will be used to calcuate the loss and to determine the accuracy of models prediction. \n",
        "- We will initiate an instance of the network called `model`. This instance will be used for training and then to save the final trained model for future inference. \n",
        "\n",
        "#####DistilbertClass\n",
        "- We will be creating a neural network with the `DistillbertClass`. \n",
        "- This network will have the DistilBERT Language model followed by a `dropout` and finally a `Linear` layer to obtain the final outputs. \n",
        "- The data will be fed to the DistilBERT Language model as defined in the dataset. \n",
        "- Final layer outputs is what will be compared to the `encoded category` to determine the accuracy of models prediction. \n",
        "- We will initiate an instance of the network called `model`. This instance will be used for training and then to save the final trained model for future inference. \n",
        "\n",
        "---\n",
        "***NOTE***\n",
        "- *It is to be noted that the outputs to the BERT and ROBERTA models are different from DISTILBERT Model implemented by the Hugging Face team. There are no `token_type_ids` generated from the tokenizer in case of DISTILBERT and also the final outputs from the network differ.*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1Ywuv7ShWqVa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DegHNyIEQxB2"
      },
      "outputs": [],
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self,model):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.AutoModel.from_pretrained(model, return_dict=False)\n",
        "        self.l2 = torch.nn.Dropout(p=0.3)\n",
        "        self.l3 = torch.nn.Linear(OUT_CHANNELS, 20)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class DistilbertClass(torch.nn.Module):\n",
        "    def __init__(self,model):\n",
        "        super(DistilbertClass, self).__init__()\n",
        "        self.l1 = transformers.AutoModel.from_pretrained(model, return_dict=False)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(OUT_CHANNELS, 20)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=ids, attention_mask=mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        \n",
        "        return output\n"
      ],
      "metadata": {
        "id": "-mPVLJq-yHhK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "fFs1rQcgBufe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTClass(MODEL_NAME) if \"distilbert\" not in MODEL_NAME else DistilbertClass(MODEL_NAME)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bcf7ce9e715b40f7ba11d263bf85de8a",
            "0eabbf7b41e943a5808f92a45e28707c",
            "acbf754fab05434c8fc21e56af574bff",
            "539abe1e79334427ac56658a68edaffa",
            "254efb8170124b8e98d62c0e0e554688",
            "c58e50e8334f457f8d0c870f1783065d",
            "243413f916464102bdee70f03eff2d6a",
            "2da4f5cfa1894cce8126f0f6d4561699",
            "4c999e19b49d464687d9d5dab0403b73",
            "2a742a307c9a498880172cdd1328fcc0",
            "11e6df8f615140a59dbf8d39fa67051a"
          ]
        },
        "id": "kRT62BLwyJq6",
        "outputId": "b5b7d9a3-b592-4965-8389-85d699341033"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcf7ce9e715b40f7ba11d263bf85de8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=1024, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "reinit_layers = 3\n",
        "if reinit_layers > 0:\n",
        "    print(f'Reinitializing Last {reinit_layers} Layers ...')\n",
        "    encoder_temp = getattr(model, 'l1')\n",
        "    for layer in encoder_temp.encoder.layer[-reinit_layers:]:\n",
        "        for module in layer.modules():\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                module.weight.data.normal_(mean=0.0, std=model.l1.config.initializer_range)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, torch.nn.Embedding):\n",
        "                module.weight.data.normal_(mean=0.0, std=model.l1.config.initializer_range)\n",
        "                if module.padding_idx is not None:\n",
        "                    module.weight.data[module.padding_idx].zero_()\n",
        "            elif isinstance(module, torch.nn.LayerNorm):\n",
        "                module.bias.data.zero_()\n",
        "                module.weight.data.fill_(1.0)\n",
        "    print('Done.!')\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "JBhXeUZYYKJq",
        "outputId": "36ab2c6e-debb-4d2c-d815-dade3be7bda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nreinit_layers = 3\\nif reinit_layers > 0:\\n    print(f'Reinitializing Last {reinit_layers} Layers ...')\\n    encoder_temp = getattr(model, 'l1')\\n    for layer in encoder_temp.encoder.layer[-reinit_layers:]:\\n        for module in layer.modules():\\n            if isinstance(module, torch.nn.Linear):\\n                module.weight.data.normal_(mean=0.0, std=model.l1.config.initializer_range)\\n                if module.bias is not None:\\n                    module.bias.data.zero_()\\n            elif isinstance(module, torch.nn.Embedding):\\n                module.weight.data.normal_(mean=0.0, std=model.l1.config.initializer_range)\\n                if module.padding_idx is not None:\\n                    module.weight.data[module.padding_idx].zero_()\\n            elif isinstance(module, torch.nn.LayerNorm):\\n                module.bias.data.zero_()\\n                module.weight.data.fill_(1.0)\\n    print('Done.!')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss Function and Optimizer\n",
        " - The Loss is defined in the next cell as `loss_fn`.\n",
        " - As defined above, the loss function used will be a combination of Binary Cross Entropy which is implemented as [BCELogits Loss](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss) in PyTorch\n",
        " - `Optimizer` is used to update the weights of the neural network to improve its performance."
      ],
      "metadata": {
        "id": "pCovzcfwW6b1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7KnNeQx6SI78"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=LEARNING_RATE, \n",
        "                  )\n",
        "                  \n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(training_loader)*EPOCHS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXDSgly3tT1O",
        "outputId": "9500a065-7f92-4b9b-8d3e-179494e9c970"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUD8j0c7WsA-"
      },
      "outputs": [],
      "source": [
        "#optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section05'></a>\n",
        "### Fine Tuning the Model\n",
        "\n",
        "Here we define a training function that trains the model on the training dataset created above, specified the number of epochs.\n",
        "\n",
        "Following events happen in this function to fine tune the neural network:\n",
        "- The dataloader passes data to the model based on the batch size. \n",
        "- Subsequent output from the model and the actual category are compared to calculate the loss. \n",
        "- Loss value is used to optimize the weights of the neurons in the network.\n",
        "- After every 100 steps the loss value is printed in the console."
      ],
      "metadata": {
        "id": "eL3We22Cgwyr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B9_DjWmfWx1q"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    size = len(training_loader.dataset)\n",
        "    model.train()\n",
        "    for batch,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        if batch%100==0:\n",
        "            current =  batch * len(data['ids'])\n",
        "            print(f\"Train loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section06'></a>\n",
        "### Validating the Model\n",
        "\n",
        "During the validation stage we check the model’s performance against the testing dataset to ensure it is learning. This testing data is the one of `args-validation.tsv`. During the validation stage at each epoch we keep track of the average loss on the validation set. This check is then used to save the best model, such as the model which registered the lowest average loss on validation set during a specific epoch. "
      ],
      "metadata": {
        "id": "mnBZM8Mu9TNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nIEoUm4aQkyl"
      },
      "outputs": [],
      "source": [
        "def validation(epoch, val_loss_min_input):\n",
        "    size = len(testing_loader.dataset)\n",
        "    num_batches = len(testing_loader)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    #fin_targets=[]\n",
        "    #fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            val_loss += loss_fn(outputs, targets).item()\n",
        "        \n",
        "        val_loss /= num_batches\n",
        "        #outputs, targets = fin_outputs, fin_targets\n",
        "        print(f\"\\nValidation loss: {val_loss:>8f}.\")\n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if val_loss <= val_loss_min_input:\n",
        "            #create checkpoint variable and add important data\n",
        "            if epoch > 0: \n",
        "                print('Validation loss decreased ({:.8f} --> {:.8f}).  Saving model ...'.format(val_loss_min_input, val_loss))\n",
        "            else: print('Saving model ...')   \n",
        "            # save best moel\n",
        "            torch.save(model.state_dict(), f\"weights_{MODEL_NAME}.pth\")\n",
        "            print(f\"Saved PyTorch Model State to weights_{MODEL_NAME}.pth\\n\")\n",
        "            val_loss_min_input = val_loss\n",
        "    \n",
        "    return val_loss_min_input\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov1_3R_pAcMo",
        "outputId": "e7c7dcbb-1249-4cab-a32c-0639c3537d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Train loss: 0.739452  [    0/ 5393]\n",
            "Train loss: 0.449379  [  800/ 5393]\n",
            "Train loss: 0.383301  [ 1600/ 5393]\n",
            "Train loss: 0.327322  [ 2400/ 5393]\n",
            "Train loss: 0.256049  [ 3200/ 5393]\n",
            "Train loss: 0.324872  [ 4000/ 5393]\n",
            "Train loss: 0.355499  [ 4800/ 5393]\n",
            "\n",
            "Validation loss: 0.339236.\n",
            "Saving model ...\n",
            "Saved PyTorch Model State to weights_roberta-large.pth\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Train loss: 0.256729  [    0/ 5393]\n",
            "Train loss: 0.305994  [  800/ 5393]\n",
            "Train loss: 0.293346  [ 1600/ 5393]\n",
            "Train loss: 0.226252  [ 2400/ 5393]\n",
            "Train loss: 0.181947  [ 3200/ 5393]\n",
            "Train loss: 0.264516  [ 4000/ 5393]\n",
            "Train loss: 0.308630  [ 4800/ 5393]\n",
            "\n",
            "Validation loss: 0.322373.\n",
            "Validation loss decreased (0.33923560 --> 0.32237340).  Saving model ...\n",
            "Saved PyTorch Model State to weights_roberta-large.pth\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Train loss: 0.207389  [    0/ 5393]\n",
            "Train loss: 0.273934  [  800/ 5393]\n",
            "Train loss: 0.256799  [ 1600/ 5393]\n",
            "Train loss: 0.186591  [ 2400/ 5393]\n",
            "Train loss: 0.171667  [ 3200/ 5393]\n",
            "Train loss: 0.235818  [ 4000/ 5393]\n",
            "Train loss: 0.269264  [ 4800/ 5393]\n",
            "\n",
            "Validation loss: 0.315344.\n",
            "Validation loss decreased (0.32237340 --> 0.31534370).  Saving model ...\n",
            "Saved PyTorch Model State to weights_roberta-large.pth\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Train loss: 0.186193  [    0/ 5393]\n",
            "Train loss: 0.255973  [  800/ 5393]\n",
            "Train loss: 0.235226  [ 1600/ 5393]\n",
            "Train loss: 0.167648  [ 2400/ 5393]\n",
            "Train loss: 0.149194  [ 3200/ 5393]\n",
            "Train loss: 0.228991  [ 4000/ 5393]\n",
            "Train loss: 0.224595  [ 4800/ 5393]\n",
            "\n",
            "Validation loss: 0.318200.\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Train loss: 0.157805  [    0/ 5393]\n",
            "Train loss: 0.210709  [  800/ 5393]\n",
            "Train loss: 0.227198  [ 1600/ 5393]\n",
            "Train loss: 0.158892  [ 2400/ 5393]\n",
            "Train loss: 0.134399  [ 3200/ 5393]\n",
            "Train loss: 0.218363  [ 4000/ 5393]\n",
            "Train loss: 0.219007  [ 4800/ 5393]\n",
            "\n",
            "Validation loss: 0.307424.\n",
            "Validation loss decreased (0.31534370 --> 0.30742354).  Saving model ...\n",
            "Saved PyTorch Model State to weights_roberta-large.pth\n",
            "\n"
          ]
        }
      ],
      "source": [
        "val_loss_min = np.inf\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train()\n",
        "    val_loss_min = validation(epoch, val_loss_min)\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELS EVALUATION"
      ],
      "metadata": {
        "id": "-1zEtHDQJz2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(loader):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "mVe17jftOsvY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT BASE"
      ],
      "metadata": {
        "id": "r-Qc0RgxJ4pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restoring the best model\n",
        "According to the average validation loss calculated at epoch, we restored the weights of the best model saved into `model.pth`. "
      ],
      "metadata": {
        "id": "4MKBGtvmF0Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# restore best model \n",
        "if MODEL_NAME == 'bert-base-uncased':\n",
        "    model = BERTClass(MODEL_NAME) if \"distilbert\" not in MODEL_NAME else DistilbertClass(MODEL_NAME)\n",
        "    model.load_state_dict(torch.load(best_weights_bert_base))\n",
        "    model = model.to(device)"
      ],
      "metadata": {
        "id": "xjRZJ1YYVeM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section07'></a>\n",
        "### Evaluating the best model\n",
        "To get a measure of our model performance we are mainly taking into account\n",
        "the F1 Macro score since is the best indicator in case of unbalanced classes as the current case."
      ],
      "metadata": {
        "id": "2DOJmHwHGQq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-base-uncased':\n",
        "    outputs, targets = test()"
      ],
      "metadata": {
        "id": "wLm-bjZAbDCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section08'></a>\n",
        "### Choosing the best threshold\n",
        "Since the outoput scores are probabilities values in the range [0,1] we need to define the best threshold to approximate each score either to 0 or to 1. \n",
        "To do that, we considered all possible threshold values between 0.1 and 0.85 with steps of 0.05 such that: all the values higher than or equal to the threshold are approximated to 1, otherwise to 0.\n",
        "Finally, we take the threshold value which gave us the highest F1 score."
      ],
      "metadata": {
        "id": "SU4WgzkXi3hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-base-uncased':\n",
        "    results = {}\n",
        "    for tr in np.arange(0.1, 0.9, 0.05):\n",
        "        tr = round(tr,2)\n",
        "        predictions = np.array(outputs) >= tr\n",
        "        f1 = f1_score(targets, predictions, average = \"macro\", zero_division = 1)\n",
        "        results[tr] = f1\n",
        "\n",
        "    for k,v in results.items():\n",
        "        print(\"THRESHOLD: {:.2f} \".format(k), \"F1 score: {:.3f}\".format(v))"
      ],
      "metadata": {
        "id": "WN3WxQ9hdFGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-base-uncased':\n",
        "    THRESHOLD = max(results, key = results.get)\n",
        "    print(\"BEST THRESHOLD:\", THRESHOLD , \"with F1 score: {:.2f}\".format(max(results.values())))"
      ],
      "metadata": {
        "id": "OalMtIzvmY53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section09'></a>\n",
        "### Classification Report"
      ],
      "metadata": {
        "id": "Dtjs2xlEnZPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-base-uncased':\n",
        "    predictions = np.array(outputs) >= THRESHOLD\n",
        "    labels = labels_test.columns[1:]\n",
        "    print(classification_report(predictions, targets, target_names = labels, zero_division=1))"
      ],
      "metadata": {
        "id": "NRLbWbpZoy6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT LARGE"
      ],
      "metadata": {
        "id": "FjzJ-MSjKAs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# restore best model \n",
        "if MODEL_NAME == 'bert-large-uncased':\n",
        "    model = BERTClass(MODEL_NAME) if \"distilbert\" not in MODEL_NAME else DistilbertClass(MODEL_NAME)\n",
        "    model.load_state_dict(torch.load('model.pth'))\n",
        "    model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2Eek5uZK-FV",
        "outputId": "80a8b561-24de-434c-8744-ecb0944ccd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-large-uncased':\n",
        "    outputs, targets = test(testing_loader)"
      ],
      "metadata": {
        "id": "io2pWLj3LCcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-large-uncased':\n",
        "    results = {}\n",
        "    for tr in np.arange(0.1, 0.9, 0.05):\n",
        "        tr = round(tr,2)\n",
        "        predictions = np.array(outputs) >= tr\n",
        "        f1 = f1_score(targets, predictions, average = \"macro\", zero_division = 1)\n",
        "        results[tr] = f1\n",
        "\n",
        "    for k,v in results.items():\n",
        "        print(\"THRESHOLD: {:.2f} \".format(k), \"F1 score: {:.3f}\".format(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmizpgxFLFba",
        "outputId": "500cecb7-e18b-416c-f235-3822b1b878ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.416\n",
            "THRESHOLD: 0.15  F1 score: 0.433\n",
            "THRESHOLD: 0.20  F1 score: 0.428\n",
            "THRESHOLD: 0.25  F1 score: 0.411\n",
            "THRESHOLD: 0.30  F1 score: 0.387\n",
            "THRESHOLD: 0.35  F1 score: 0.363\n",
            "THRESHOLD: 0.40  F1 score: 0.341\n",
            "THRESHOLD: 0.45  F1 score: 0.325\n",
            "THRESHOLD: 0.50  F1 score: 0.306\n",
            "THRESHOLD: 0.55  F1 score: 0.285\n",
            "THRESHOLD: 0.60  F1 score: 0.260\n",
            "THRESHOLD: 0.65  F1 score: 0.236\n",
            "THRESHOLD: 0.70  F1 score: 0.197\n",
            "THRESHOLD: 0.75  F1 score: 0.158\n",
            "THRESHOLD: 0.80  F1 score: 0.119\n",
            "THRESHOLD: 0.85  F1 score: 0.087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-large-uncased':\n",
        "    THRESHOLD = max(results, key = results.get)\n",
        "    print(\"BEST THRESHOLD:\", THRESHOLD , \"with F1 score: {:.2f}\".format(max(results.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHez7WI6LMDm",
        "outputId": "be25c0d4-e08a-4a4f-8916-45851f9dc904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST THRESHOLD: 0.15 with F1 score: 0.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'bert-large-uncased':\n",
        "    predictions = np.array(outputs) >= THRESHOLD\n",
        "    labels = labels_test.columns[1:]\n",
        "    print(classification_report(predictions, targets, target_names = labels, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t1EB259RRCW",
        "outputId": "eb265190-52fa-4224-ef35-dc84029ecacd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.80      0.30      0.44       666\n",
            "    Self-direction: action       0.79      0.40      0.53       981\n",
            "               Stimulation       0.22      0.43      0.29        69\n",
            "                  Hedonism       0.23      0.43      0.30        56\n",
            "               Achievement       0.89      0.45      0.59      1150\n",
            "          Power: dominance       0.43      0.35      0.38       202\n",
            "          Power: resources       0.78      0.34      0.48       301\n",
            "                      Face       0.15      0.25      0.19        80\n",
            "        Security: personal       0.94      0.51      0.66      1399\n",
            "        Security: societal       0.82      0.46      0.59       882\n",
            "                 Tradition       0.44      0.40      0.42       186\n",
            "         Conformity: rules       0.84      0.40      0.54       959\n",
            " Conformity: interpersonal       0.17      0.33      0.22        30\n",
            "                  Humility       0.20      0.16      0.18       161\n",
            "       Benevolence: caring       0.97      0.37      0.53      1656\n",
            "Benevolence: dependability       0.70      0.19      0.30       989\n",
            "     Universalism: concern       0.95      0.43      0.60      1513\n",
            "      Universalism: nature       0.72      0.67      0.69       136\n",
            "   Universalism: tolerance       0.46      0.24      0.31       426\n",
            " Universalism: objectivity       0.78      0.28      0.41      1029\n",
            "\n",
            "                 micro avg       0.77      0.38      0.51     12871\n",
            "                 macro avg       0.61      0.37      0.43     12871\n",
            "              weighted avg       0.81      0.38      0.51     12871\n",
            "               samples avg       0.80      0.39      0.50     12871\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROBERTA BASE "
      ],
      "metadata": {
        "id": "92PhwOEOL9YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# restore best model \n",
        "if MODEL_NAME == 'roberta-base':\n",
        "    model = BERTClass(MODEL_NAME) if \"distilbert\" not in MODEL_NAME else DistilbertClass(MODEL_NAME)\n",
        "    model.load_state_dict(torch.load(f'weights_{MODEL_NAME}.pth'))\n",
        "    model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3971TZnuMC8X",
        "outputId": "6c5160fd-a400-4367-fe7b-4eb4681db457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-base':\n",
        "    outputs, targets = test(testing_loader)"
      ],
      "metadata": {
        "id": "xpKgPUiJMD87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-base':\n",
        "    results = {}\n",
        "    for tr in np.arange(0.1, 0.9, 0.05):\n",
        "        tr = round(tr,2)\n",
        "        predictions = np.array(outputs) >= tr\n",
        "        f1 = f1_score(targets, predictions, average = \"macro\", zero_division = 1)\n",
        "        results[tr] = f1\n",
        "\n",
        "    for k,v in results.items():\n",
        "        print(\"THRESHOLD: {:.2f} \".format(k), \"F1 score: {:.3f}\".format(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkX2amJNMF1f",
        "outputId": "efab183a-71f9-45a5-af80-e347346f229c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.422\n",
            "THRESHOLD: 0.15  F1 score: 0.449\n",
            "THRESHOLD: 0.20  F1 score: 0.447\n",
            "THRESHOLD: 0.25  F1 score: 0.434\n",
            "THRESHOLD: 0.30  F1 score: 0.424\n",
            "THRESHOLD: 0.35  F1 score: 0.398\n",
            "THRESHOLD: 0.40  F1 score: 0.379\n",
            "THRESHOLD: 0.45  F1 score: 0.361\n",
            "THRESHOLD: 0.50  F1 score: 0.339\n",
            "THRESHOLD: 0.55  F1 score: 0.320\n",
            "THRESHOLD: 0.60  F1 score: 0.303\n",
            "THRESHOLD: 0.65  F1 score: 0.283\n",
            "THRESHOLD: 0.70  F1 score: 0.257\n",
            "THRESHOLD: 0.75  F1 score: 0.224\n",
            "THRESHOLD: 0.80  F1 score: 0.186\n",
            "THRESHOLD: 0.85  F1 score: 0.139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-base':\n",
        "    THRESHOLD = max(results, key = results.get)\n",
        "    print(\"BEST THRESHOLD:\", THRESHOLD , \"with F1 score: {:.2f}\".format(max(results.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8u-WFKZMIAT",
        "outputId": "1dedc215-63fe-492f-cceb-aa7c1989ccb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST THRESHOLD: 0.15 with F1 score: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-base':\n",
        "    predictions = np.array(outputs) >= THRESHOLD\n",
        "    labels = labels_test.columns[1:]\n",
        "    print(classification_report(predictions, targets, target_names = labels, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_8XT4hURTDQ",
        "outputId": "cc4f3621-e8cd-4557-c8fe-ce92e7f34361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.81      0.29      0.43       699\n",
            "    Self-direction: action       0.80      0.43      0.56       924\n",
            "               Stimulation       0.30      0.39      0.34       106\n",
            "                  Hedonism       0.37      0.36      0.36       107\n",
            "               Achievement       0.87      0.47      0.61      1066\n",
            "          Power: dominance       0.41      0.30      0.34       226\n",
            "          Power: resources       0.71      0.36      0.48       258\n",
            "                      Face       0.22      0.25      0.23       110\n",
            "        Security: personal       0.94      0.53      0.68      1347\n",
            "        Security: societal       0.80      0.51      0.62       771\n",
            "                 Tradition       0.49      0.37      0.42       229\n",
            "         Conformity: rules       0.76      0.45      0.57       767\n",
            " Conformity: interpersonal       0.10      0.32      0.15        19\n",
            "                  Humility       0.24      0.17      0.20       178\n",
            "       Benevolence: caring       0.93      0.39      0.55      1499\n",
            "Benevolence: dependability       0.63      0.22      0.33       768\n",
            "     Universalism: concern       0.92      0.50      0.65      1264\n",
            "      Universalism: nature       0.72      0.67      0.69       135\n",
            "   Universalism: tolerance       0.37      0.27      0.31       306\n",
            " Universalism: objectivity       0.78      0.32      0.45       915\n",
            "\n",
            "                 micro avg       0.75      0.41      0.53     11694\n",
            "                 macro avg       0.61      0.38      0.45     11694\n",
            "              weighted avg       0.79      0.41      0.53     11694\n",
            "               samples avg       0.79      0.43      0.53     11694\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROBERTA LARGE"
      ],
      "metadata": {
        "id": "8sdEprw1NBhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# restore best model \n",
        "if MODEL_NAME == 'roberta-large':\n",
        "    model = BERTClass(MODEL_NAME) if \"distilbert\" not in MODEL_NAME else DistilbertClass(MODEL_NAME)\n",
        "    model.load_state_dict(torch.load(f'weights_{MODEL_NAME}.pth'))\n",
        "    model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFOmpDWNFtQ",
        "outputId": "815ffab5-877c-46ab-8885-bb71e3ad1877"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    outputs, targets = test(training_loader)"
      ],
      "metadata": {
        "id": "HrseZYoxNGfh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    results = {}\n",
        "    for tr in np.arange(0.1, 0.9, 0.05):\n",
        "        tr = round(tr,2)\n",
        "        predictions = np.array(outputs) >= tr\n",
        "        f1 = f1_score(targets, predictions, average = \"macro\", zero_division = 1)\n",
        "        results[tr] = f1\n",
        "\n",
        "    for k,v in results.items():\n",
        "        print(\"THRESHOLD: {:.2f} \".format(k), \"F1 score: {:.3f}\".format(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tqfApYSNIhM",
        "outputId": "872c6491-ad2f-4104-d11a-2099e6378508"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.623\n",
            "THRESHOLD: 0.15  F1 score: 0.687\n",
            "THRESHOLD: 0.20  F1 score: 0.717\n",
            "THRESHOLD: 0.25  F1 score: 0.726\n",
            "THRESHOLD: 0.30  F1 score: 0.726\n",
            "THRESHOLD: 0.35  F1 score: 0.712\n",
            "THRESHOLD: 0.40  F1 score: 0.698\n",
            "THRESHOLD: 0.45  F1 score: 0.678\n",
            "THRESHOLD: 0.50  F1 score: 0.651\n",
            "THRESHOLD: 0.55  F1 score: 0.626\n",
            "THRESHOLD: 0.60  F1 score: 0.590\n",
            "THRESHOLD: 0.65  F1 score: 0.552\n",
            "THRESHOLD: 0.70  F1 score: 0.511\n",
            "THRESHOLD: 0.75  F1 score: 0.463\n",
            "THRESHOLD: 0.80  F1 score: 0.408\n",
            "THRESHOLD: 0.85  F1 score: 0.339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    THRESHOLD = max(results, key = results.get)\n",
        "    print(\"BEST THRESHOLD:\", THRESHOLD , \"with F1 score: {:.2f}\".format(max(results.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb6gOU8fNK0V",
        "outputId": "35f6f486-38ae-45d7-885f-f07abea9fc69"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST THRESHOLD: 0.3 with F1 score: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    predictions = np.array(outputs) >= THRESHOLD\n",
        "    labels = labels_test.columns[1:]\n",
        "    print(classification_report(targets, predictions, target_names = labels, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLgyUXd9RUPj",
        "outputId": "e221c95d-edb8-42af-dd2a-9ba1a7690a2d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.76      0.89      0.82       988\n",
            "    Self-direction: action       0.83      0.87      0.85      1395\n",
            "               Stimulation       0.69      0.31      0.43       247\n",
            "                  Hedonism       0.82      0.55      0.66       172\n",
            "               Achievement       0.75      0.91      0.82      1512\n",
            "          Power: dominance       0.71      0.53      0.61       610\n",
            "          Power: resources       0.78      0.85      0.81       625\n",
            "                      Face       0.73      0.35      0.48       382\n",
            "        Security: personal       0.82      0.90      0.86      2000\n",
            "        Security: societal       0.85      0.87      0.86      1728\n",
            "                 Tradition       0.88      0.77      0.82       568\n",
            "         Conformity: rules       0.80      0.78      0.79      1177\n",
            " Conformity: interpersonal       0.79      0.64      0.71       207\n",
            "                  Humility       0.77      0.51      0.62       395\n",
            "       Benevolence: caring       0.69      0.76      0.73      1332\n",
            "Benevolence: dependability       0.62      0.51      0.56       806\n",
            "     Universalism: concern       0.81      0.92      0.86      2081\n",
            "      Universalism: nature       0.95      0.87      0.91       427\n",
            "   Universalism: tolerance       0.76      0.58      0.66       664\n",
            " Universalism: objectivity       0.64      0.71      0.67      1054\n",
            "\n",
            "                 micro avg       0.78      0.79      0.78     18370\n",
            "                 macro avg       0.77      0.70      0.73     18370\n",
            "              weighted avg       0.78      0.79      0.78     18370\n",
            "               samples avg       0.80      0.82      0.78     18370\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    outputs, targets = test(testing_loader)"
      ],
      "metadata": {
        "id": "DQl7xlCPlxXS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    results = {}\n",
        "    for tr in np.arange(0.1, 0.9, 0.05):\n",
        "        tr = round(tr,2)\n",
        "        predictions = np.array(outputs) >= tr\n",
        "        f1 = f1_score(targets, predictions, average = \"macro\", zero_division = 1)\n",
        "        results[tr] = f1\n",
        "\n",
        "    for k,v in results.items():\n",
        "        print(\"THRESHOLD: {:.2f} \".format(k), \"F1 score: {:.3f}\".format(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB-vOma2l1cO",
        "outputId": "ed465851-bb4d-4fc1-b51e-a55912fae543"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.479\n",
            "THRESHOLD: 0.15  F1 score: 0.501\n",
            "THRESHOLD: 0.20  F1 score: 0.504\n",
            "THRESHOLD: 0.25  F1 score: 0.500\n",
            "THRESHOLD: 0.30  F1 score: 0.488\n",
            "THRESHOLD: 0.35  F1 score: 0.472\n",
            "THRESHOLD: 0.40  F1 score: 0.457\n",
            "THRESHOLD: 0.45  F1 score: 0.444\n",
            "THRESHOLD: 0.50  F1 score: 0.433\n",
            "THRESHOLD: 0.55  F1 score: 0.412\n",
            "THRESHOLD: 0.60  F1 score: 0.394\n",
            "THRESHOLD: 0.65  F1 score: 0.378\n",
            "THRESHOLD: 0.70  F1 score: 0.350\n",
            "THRESHOLD: 0.75  F1 score: 0.323\n",
            "THRESHOLD: 0.80  F1 score: 0.294\n",
            "THRESHOLD: 0.85  F1 score: 0.260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    THRESHOLD = max(results, key = results.get)\n",
        "    print(\"BEST THRESHOLD:\", THRESHOLD , \"with F1 score: {:.2f}\".format(max(results.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAqn1DG7l3P0",
        "outputId": "be35ce07-6084-4efa-a0c1-289920235eac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST THRESHOLD: 0.2 with F1 score: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'roberta-large':\n",
        "    predictions = np.array(outputs) >= THRESHOLD\n",
        "    labels = labels_test.columns[1:]\n",
        "    print(classification_report(targets, predictions, target_names = labels, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkADaWPUl4w9",
        "outputId": "44bfd54b-9c20-4419-c3a2-9efc33ee9fb9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.44      0.70      0.54       251\n",
            "    Self-direction: action       0.53      0.69      0.60       496\n",
            "               Stimulation       0.51      0.28      0.36       138\n",
            "                  Hedonism       0.50      0.42      0.46       103\n",
            "               Achievement       0.55      0.83      0.66       575\n",
            "          Power: dominance       0.37      0.38      0.37       164\n",
            "          Power: resources       0.42      0.61      0.50       132\n",
            "                      Face       0.36      0.22      0.27       130\n",
            "        Security: personal       0.61      0.90      0.73       759\n",
            "        Security: societal       0.57      0.75      0.65       488\n",
            "                 Tradition       0.55      0.41      0.47       172\n",
            "         Conformity: rules       0.56      0.73      0.64       455\n",
            " Conformity: interpersonal       0.54      0.35      0.42        60\n",
            "                  Humility       0.23      0.13      0.16       127\n",
            "       Benevolence: caring       0.49      0.76      0.59       633\n",
            "Benevolence: dependability       0.30      0.50      0.37       268\n",
            "     Universalism: concern       0.58      0.86      0.69       687\n",
            "      Universalism: nature       0.74      0.73      0.74       127\n",
            "   Universalism: tolerance       0.35      0.36      0.36       223\n",
            " Universalism: objectivity       0.40      0.66      0.50       371\n",
            "\n",
            "                 micro avg       0.51      0.69      0.59      6359\n",
            "                 macro avg       0.48      0.56      0.50      6359\n",
            "              weighted avg       0.51      0.69      0.58      6359\n",
            "               samples avg       0.54      0.73      0.59      6359\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DISTILBERT"
      ],
      "metadata": {
        "id": "B2LJh7_3QC4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# restore best model \n",
        "if MODEL_NAME == 'distilbert-base-uncased':\n",
        "    model = BERTClass(MODEL_NAME) if \"distilbert\" not in MODEL_NAME else DistilbertClass(MODEL_NAME)\n",
        "    model.load_state_dict(torch.load('model.pth'))\n",
        "    model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfUGx_e-PtMh",
        "outputId": "bacece04-c7c6-4d0b-9c56-1139f65b68ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'distilbert-base-uncased':\n",
        "    outputs, targets = test(testing_loader)"
      ],
      "metadata": {
        "id": "Iw-bz29NPvci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'distilbert-base-uncased':\n",
        "    results = {}\n",
        "    for tr in np.arange(0.1, 0.9, 0.05):\n",
        "        tr = round(tr,2)\n",
        "        predictions = np.array(outputs) >= tr\n",
        "        f1 = f1_score(targets, predictions, average = \"macro\", zero_division = 1)\n",
        "        results[tr] = f1\n",
        "\n",
        "    for k,v in results.items():\n",
        "        print(\"THRESHOLD: {:.2f} \".format(k), \"F1 score: {:.3f}\".format(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3RWjsiqPysE",
        "outputId": "638eccda-7153-48ee-8047-d3fa606dbe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.407\n",
            "THRESHOLD: 0.15  F1 score: 0.410\n",
            "THRESHOLD: 0.20  F1 score: 0.404\n",
            "THRESHOLD: 0.25  F1 score: 0.394\n",
            "THRESHOLD: 0.30  F1 score: 0.375\n",
            "THRESHOLD: 0.35  F1 score: 0.353\n",
            "THRESHOLD: 0.40  F1 score: 0.332\n",
            "THRESHOLD: 0.45  F1 score: 0.313\n",
            "THRESHOLD: 0.50  F1 score: 0.296\n",
            "THRESHOLD: 0.55  F1 score: 0.275\n",
            "THRESHOLD: 0.60  F1 score: 0.253\n",
            "THRESHOLD: 0.65  F1 score: 0.222\n",
            "THRESHOLD: 0.70  F1 score: 0.188\n",
            "THRESHOLD: 0.75  F1 score: 0.158\n",
            "THRESHOLD: 0.80  F1 score: 0.116\n",
            "THRESHOLD: 0.85  F1 score: 0.082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'distilbert-base-uncased':\n",
        "    THRESHOLD = max(results, key = results.get)\n",
        "    print(\"BEST THRESHOLD:\", THRESHOLD , \"with F1 score: {:.2f}\".format(max(results.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rGi_OmMPzU-",
        "outputId": "f977c998-a42c-4677-b592-72a05bc5f5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST THRESHOLD: 0.15 with F1 score: 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_NAME == 'distilbert-base-uncased':\n",
        "    predictions = np.array(outputs) >= THRESHOLD\n",
        "    labels = labels_test.columns[1:]\n",
        "    print(classification_report(predictions, targets, target_names = labels, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXoEkHHPRVUl",
        "outputId": "da8f0c3f-a44c-4dcb-8787-1ccf6933cad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.69      0.34      0.46       506\n",
            "    Self-direction: action       0.73      0.40      0.52       895\n",
            "               Stimulation       0.11      0.42      0.17        36\n",
            "                  Hedonism       0.18      0.63      0.29        30\n",
            "               Achievement       0.86      0.44      0.59      1110\n",
            "          Power: dominance       0.34      0.32      0.33       175\n",
            "          Power: resources       0.80      0.37      0.51       283\n",
            "                      Face       0.12      0.24      0.16        67\n",
            "        Security: personal       0.94      0.53      0.68      1345\n",
            "        Security: societal       0.83      0.44      0.58       916\n",
            "                 Tradition       0.43      0.38      0.40       194\n",
            "         Conformity: rules       0.84      0.39      0.53       977\n",
            " Conformity: interpersonal       0.07      0.20      0.10        20\n",
            "                  Humility       0.09      0.11      0.10       107\n",
            "       Benevolence: caring       0.95      0.38      0.54      1590\n",
            "Benevolence: dependability       0.66      0.20      0.31       887\n",
            "     Universalism: concern       0.96      0.43      0.59      1537\n",
            "      Universalism: nature       0.67      0.65      0.66       131\n",
            "   Universalism: tolerance       0.22      0.26      0.23       186\n",
            " Universalism: objectivity       0.78      0.31      0.45       928\n",
            "\n",
            "                 micro avg       0.74      0.39      0.51     11920\n",
            "                 macro avg       0.56      0.37      0.41     11920\n",
            "              weighted avg       0.81      0.39      0.52     11920\n",
            "               samples avg       0.77      0.40      0.50     11920\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('fastai': conda)",
      "language": "python",
      "name": "python37664bitfastaiconda149f4ca18fae45818735beadf08062d0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bc33332ccc849ef874a48158a14a4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bee90653ad614fae92d67206bad420c9",
              "IPY_MODEL_f84b2d3c97f04661933a8759ebc87f08",
              "IPY_MODEL_fde85dd33592434288703e0fe28ed19e"
            ],
            "layout": "IPY_MODEL_15b4780b911443d38d4b8d136412146f"
          }
        },
        "bee90653ad614fae92d67206bad420c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d422c5b0e00643f781ba12749c83821c",
            "placeholder": "​",
            "style": "IPY_MODEL_d145e7dda365482cbd08fcfc7e5f4529",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "f84b2d3c97f04661933a8759ebc87f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba169da0b5a4018aa793e756d6be2d7",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0210959d908848b3a5ade43f4d6abb5b",
            "value": 482
          }
        },
        "fde85dd33592434288703e0fe28ed19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5010691d070417f97c7f644c1a205da",
            "placeholder": "​",
            "style": "IPY_MODEL_2bea7e1a55e44f668ae331248dc73d6f",
            "value": " 482/482 [00:00&lt;00:00, 6.94kB/s]"
          }
        },
        "15b4780b911443d38d4b8d136412146f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d422c5b0e00643f781ba12749c83821c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d145e7dda365482cbd08fcfc7e5f4529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ba169da0b5a4018aa793e756d6be2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0210959d908848b3a5ade43f4d6abb5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5010691d070417f97c7f644c1a205da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bea7e1a55e44f668ae331248dc73d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6407b2bc74fe41248604ca37a07d931c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6056d2a88cf4976ba1c6120b6b67e28",
              "IPY_MODEL_b41234f575b24bd699501c8311ebb182",
              "IPY_MODEL_21ddf52d62e54a0787f9a4460ad5fe99"
            ],
            "layout": "IPY_MODEL_0f9c4064572d4a698a5ac91ea3ca06f8"
          }
        },
        "b6056d2a88cf4976ba1c6120b6b67e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef5de2b5c424c0280a98eecca5df1f5",
            "placeholder": "​",
            "style": "IPY_MODEL_c98adddbc75b457bbec5b8f2d8d2153e",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "b41234f575b24bd699501c8311ebb182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e1bfecf47d4998b3111d7956dd40b8",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36dbd4a1a5d74ec5a8a2bc4e1f97f184",
            "value": 898823
          }
        },
        "21ddf52d62e54a0787f9a4460ad5fe99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf52283a3b0c44f4ae56380966b55041",
            "placeholder": "​",
            "style": "IPY_MODEL_74b62adfdb5d4b4794d16077f1eba7b2",
            "value": " 899k/899k [00:01&lt;00:00, 790kB/s]"
          }
        },
        "0f9c4064572d4a698a5ac91ea3ca06f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ef5de2b5c424c0280a98eecca5df1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98adddbc75b457bbec5b8f2d8d2153e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e1bfecf47d4998b3111d7956dd40b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36dbd4a1a5d74ec5a8a2bc4e1f97f184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf52283a3b0c44f4ae56380966b55041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b62adfdb5d4b4794d16077f1eba7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71d288315f0348c6a5caa1c64e71f1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e87f61899b9245f890c8234100f82ff6",
              "IPY_MODEL_81152743d6344bac88ea081a23727166",
              "IPY_MODEL_3d8dbc465730415687f4cb13ed2b2791"
            ],
            "layout": "IPY_MODEL_8329fc4a6777404998b0ed61cb0c92f0"
          }
        },
        "e87f61899b9245f890c8234100f82ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63d947cc07f94e2a9a645bc3076303e9",
            "placeholder": "​",
            "style": "IPY_MODEL_6587c79566de48f29624b5ba28e847e2",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "81152743d6344bac88ea081a23727166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_495ca330ee8a42989f3471551b0f16ae",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d9523b5ec454ddca722f6ec602ecca4",
            "value": 456318
          }
        },
        "3d8dbc465730415687f4cb13ed2b2791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a679f22327344ebebd23dec367ac49f5",
            "placeholder": "​",
            "style": "IPY_MODEL_0381019a16254c5e97befce45fd05d58",
            "value": " 456k/456k [00:00&lt;00:00, 493kB/s]"
          }
        },
        "8329fc4a6777404998b0ed61cb0c92f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d947cc07f94e2a9a645bc3076303e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6587c79566de48f29624b5ba28e847e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "495ca330ee8a42989f3471551b0f16ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d9523b5ec454ddca722f6ec602ecca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a679f22327344ebebd23dec367ac49f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0381019a16254c5e97befce45fd05d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd06cb104d0649fab7ee39a0aa0e0799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64b8e628b5e94716ba6c99ad836e47d5",
              "IPY_MODEL_4e1c35f5bed446cdbd9f091095714dda",
              "IPY_MODEL_76e5f05dd7344984b57b021b86a70322"
            ],
            "layout": "IPY_MODEL_222fc947ee7b436782c43a53c6252cff"
          }
        },
        "64b8e628b5e94716ba6c99ad836e47d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e17d5a70e2644c1fab29f6b9755334ac",
            "placeholder": "​",
            "style": "IPY_MODEL_dfbf7a39c83440bb9f9e0ef278a78669",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "4e1c35f5bed446cdbd9f091095714dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e0d0ded1a94b08848a784eb8050d4a",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_126654647bc649b1a303d1e96d2c858e",
            "value": 1355863
          }
        },
        "76e5f05dd7344984b57b021b86a70322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb118445265a457997a1e61c6d22170d",
            "placeholder": "​",
            "style": "IPY_MODEL_4383abd1855444438db41171f1ec4c64",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.01MB/s]"
          }
        },
        "222fc947ee7b436782c43a53c6252cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17d5a70e2644c1fab29f6b9755334ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfbf7a39c83440bb9f9e0ef278a78669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26e0d0ded1a94b08848a784eb8050d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126654647bc649b1a303d1e96d2c858e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb118445265a457997a1e61c6d22170d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4383abd1855444438db41171f1ec4c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf7ce9e715b40f7ba11d263bf85de8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eabbf7b41e943a5808f92a45e28707c",
              "IPY_MODEL_acbf754fab05434c8fc21e56af574bff",
              "IPY_MODEL_539abe1e79334427ac56658a68edaffa"
            ],
            "layout": "IPY_MODEL_254efb8170124b8e98d62c0e0e554688"
          }
        },
        "0eabbf7b41e943a5808f92a45e28707c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c58e50e8334f457f8d0c870f1783065d",
            "placeholder": "​",
            "style": "IPY_MODEL_243413f916464102bdee70f03eff2d6a",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "acbf754fab05434c8fc21e56af574bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da4f5cfa1894cce8126f0f6d4561699",
            "max": 1425941629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c999e19b49d464687d9d5dab0403b73",
            "value": 1425941629
          }
        },
        "539abe1e79334427ac56658a68edaffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a742a307c9a498880172cdd1328fcc0",
            "placeholder": "​",
            "style": "IPY_MODEL_11e6df8f615140a59dbf8d39fa67051a",
            "value": " 1.43G/1.43G [00:18&lt;00:00, 70.9MB/s]"
          }
        },
        "254efb8170124b8e98d62c0e0e554688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58e50e8334f457f8d0c870f1783065d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243413f916464102bdee70f03eff2d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2da4f5cfa1894cce8126f0f6d4561699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c999e19b49d464687d9d5dab0403b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a742a307c9a498880172cdd1328fcc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e6df8f615140a59dbf8d39fa67051a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}